{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Fetch the URL\n",
    "url = \"https://www.indeed.com/jobs?q=python&l=Remote&ts=1727179231724&from=searchOnHP&rq=1&rsIdx=0&fromage=last&vjk=52108bd7282a4c2d\"\n",
    "result = requests.get(url)\n",
    "\n",
    "# Save page content/markup\n",
    "src = result.content\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(src, 'lxml')\n",
    "\n",
    "# Find all job titles by targeting the correct class name and nested span\n",
    "job_titles = soup.find_all('h2', {'class': 'jobTitle css-198pbd eu4oa1w0'})\n",
    "\n",
    "# Extract the text from the <span> inside the <h2>\n",
    "job_title_list = [title.find('span').text.strip() for title in job_titles]\n",
    "\n",
    "# Print the job titles\n",
    "print(job_title_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=129.0.6668.59)\nStacktrace:\n\tGetHandleVerifier [0x00007FF750ACFDA5+29557]\n\t(No symbol) [0x00007FF750A42240]\n\t(No symbol) [0x00007FF7508FB6EA]\n\t(No symbol) [0x00007FF7508CFCD5]\n\t(No symbol) [0x00007FF75097F167]\n\t(No symbol) [0x00007FF7509981A1]\n\t(No symbol) [0x00007FF7509772A3]\n\t(No symbol) [0x00007FF7509412DF]\n\t(No symbol) [0x00007FF750942451]\n\tGetHandleVerifier [0x00007FF750DFDCBD+3363469]\n\tGetHandleVerifier [0x00007FF750E49B47+3674391]\n\tGetHandleVerifier [0x00007FF750E3EAEB+3629243]\n\tGetHandleVerifier [0x00007FF750B8FC66+815670]\n\t(No symbol) [0x00007FF750A4D6EF]\n\t(No symbol) [0x00007FF750A492B4]\n\t(No symbol) [0x00007FF750A49450]\n\t(No symbol) [0x00007FF750A381FF]\n\tBaseThreadInitThunk [0x00007FFAC2DA7374+20]\n\tRtlUserThreadStart [0x00007FFAC315CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Find all job titles on the page\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m job_titles \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjobTitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Extract and print job titles\u001b[39;00m\n\u001b[0;32m     24\u001b[0m job_title_list \u001b[38;5;241m=\u001b[39m [title\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m title \u001b[38;5;129;01min\u001b[39;00m job_titles]\n",
      "File \u001b[1;32mc:\\Users\\NIPEAL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:778\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    774\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[1;32mc:\\Users\\NIPEAL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\NIPEAL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=129.0.6668.59)\nStacktrace:\n\tGetHandleVerifier [0x00007FF750ACFDA5+29557]\n\t(No symbol) [0x00007FF750A42240]\n\t(No symbol) [0x00007FF7508FB6EA]\n\t(No symbol) [0x00007FF7508CFCD5]\n\t(No symbol) [0x00007FF75097F167]\n\t(No symbol) [0x00007FF7509981A1]\n\t(No symbol) [0x00007FF7509772A3]\n\t(No symbol) [0x00007FF7509412DF]\n\t(No symbol) [0x00007FF750942451]\n\tGetHandleVerifier [0x00007FF750DFDCBD+3363469]\n\tGetHandleVerifier [0x00007FF750E49B47+3674391]\n\tGetHandleVerifier [0x00007FF750E3EAEB+3629243]\n\tGetHandleVerifier [0x00007FF750B8FC66+815670]\n\t(No symbol) [0x00007FF750A4D6EF]\n\t(No symbol) [0x00007FF750A492B4]\n\t(No symbol) [0x00007FF750A49450]\n\t(No symbol) [0x00007FF750A381FF]\n\tBaseThreadInitThunk [0x00007FFAC2DA7374+20]\n\tRtlUserThreadStart [0x00007FFAC315CC91+33]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Path to your downloaded ChromeDriver\n",
    "chrome_driver_path =\"C:/chromedriver-win64/chromedriver.exe\"\n",
    "\n",
    "# Set up the WebDriver service\n",
    "service = Service(chrome_driver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open the Indeed page with Selenium\n",
    "url = \"https://www.indeed.com/jobs?q=python&l=Remote&ts=1727179231724&from=searchOnHP&rq=1&rsIdx=0&fromage=last&vjk=52108bd7282a4c2d\"\n",
    "driver.get(url)\n",
    "\n",
    "# Allow time for the page to fully load\n",
    "time.sleep(5)\n",
    "\n",
    "# Find all job titles on the page\n",
    "job_titles = driver.find_elements(By.CLASS_NAME, 'jobTitle')\n",
    "\n",
    "# Extract and print job titles\n",
    "job_title_list = [title.text for title in job_titles]\n",
    "for job in job_title_list:\n",
    "    print(job)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Set the path to the ChromeDriver\n",
    "chrome_driver_path = \"C:/chromedriver-win64/chromedriver.exe\"\n",
    "# Set up the WebDriver service\n",
    "service = Service(chrome_driver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open a website (e.g., Indeed)\n",
    "url = \"https://www.indeed.com/jobs?q=python&l=Remote\"\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nile Bits, LLC -', 'Pyramids Pharmacy  -', 'coto -', 'Afaqy -', 'RDI -', 'RDI -', 'Bright Creations -', 'Al Soug-Cashi -', 'Storlytics  -', 'RDI -', 'CodeTreps -', 'CONSULTIX  -', 'willys kitchen-Egypt -', 'EpsilonAI -', 'Al Ateeq Software -']\n",
      "\n",
      "['Senior Python Developer', 'Full Stack Developer - Python', 'Python Artisan Developer', 'Python Developer', 'Full-Stack Python Team Leader (Django/React)', 'Senior Full-Stack Python (Django/React) in KSA', 'DAZU Pay - Python Developer (FinTech)', 'Junior data engineer', 'Senior Renewable Energy Engineer', 'Junior Python Developer', 'Instructor for Kids , ages 7-17 (with focus on schools)', 'Full Stack Software Engineer - Internet of Things (IoT)', 'Senior Odoo Developer', 'Data Science Instructor', 'Data Scientist']\n",
      "\n",
      "['Full TimeRemoteExperienced · 3 - 10 Yrs of Exp · IT/Software Development · Engineering - Telecom/Technology · AWS · APIs · RESTful · Python · Software Engineering', 'Full TimeHybridExperienced · 2 - 5 Yrs of Exp · IT/Software Development · Python · Django · React · AWS · Docker · Github', 'Full TimeRemoteExperienced · 3 - 6 Yrs of Exp · IT/Software Development · Django · API · AI · Data Processing · Computer Science · Docker · Engineering · Information Technology (IT) · MongoDB', 'Full TimeHybridExperienced · 1 - 3 Yrs of Exp · IT/Software Development · Computer Science · Software Development · Python', 'Full TimeOn-siteExperienced · 5 - 8 Yrs of Exp · IT/Software Development · Engineering - Telecom/Technology · React · Django · Full Stack Development · Information Technology (IT) · Computer Science · RESTful API · Microservice Architecture · Database Systems', 'Full TimeOn-siteExperienced · 5 - 8 Yrs of Exp · IT/Software Development · Engineering - Telecom/Technology · React · Django · Full Stack Development · Information Technology (IT) · Computer Science · RESTful API · Microservice Architecture · Database Systems', 'Full TimeFreelance / ProjectHybridEntry Level · 2+ Yrs of Exp · IT/Software Development · Engineering - Telecom/Technology · Python · Django · Flask · Python Scripting · Web Scraping · WWeb Scraping · CI · Computer Science', 'Full TimeOn-siteEntry Level · 1 - 3 Yrs of Exp · IT/Software Development · Engineering - Telecom/Technology · AWS · BI · Data · Engineering · Python · SQL · Database · Software Development', 'Full TimeRemoteExperienced · 3 - 10 Yrs of Exp · Engineering - Mechanical/Electrical · English · AutoCAD · Electrical Engineering · Renewable Energy · Power · PVsyst · Python', 'Full TimeHybridEntry Level · 1 - 3 Yrs of Exp · Business Development · IT/Software Development · Engineering - Telecom/Technology · Python · MySQL · JavaScript · React · Angular · RESTful · Django', 'Full TimePart TimeOn-siteEntry Level · 1 - 3 Yrs of Exp · IT/Software Development · Education/Teaching · Training/Instructor · Computer Science · Entrepreneurship · Education · Programming · Teaching · Training · Instructor', 'Full TimeOn-siteExperienced · 3 - 5 Yrs of Exp · IT/Software Development · Computer Science · Full Stack · Information Technology (IT) · JavaScript · Software · Software Development · SQL · Python · Development', 'Full TimeOn-siteExperienced · 5 - 7 Yrs of Exp · males_only · IT/Software Development · Engineering - Telecom/Technology · Information Technology (IT) · Software Development · Odoo · JavaScript · HTML · Python · XML · Software Engineering', 'Full TimePart TimeExperienced · 1+ Yrs of Exp · IT/Software Development · Engineering - Telecom/Technology · Training/Instructor · Data Science · Computer Science · Computer Engineering · Python · Machine Learning · Deep Learning · Artificial Intelligence (AI)', 'Full TimeOn-siteExperienced · 7 - 10 Yrs of Exp · IT/Software Development · Analyst/Research · Engineering - Telecom/Technology · Data Mining · Computer Science · Data Science · Information Technology (IT) · Python · SQL · Research']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from itertools import zip_longest\n",
    "\n",
    "#fetch url\n",
    "result=requests.get(\"https://wuzzuf.net/search/jobs/?q=python&a=hpb\")\n",
    "\n",
    "#save page content/markup\n",
    "src= result.content\n",
    "\n",
    "#create soup object to parse content\n",
    "soup=BeautifulSoup(src,'lxml')\n",
    "\n",
    "\n",
    "job_title=[]\n",
    "company_name=[]\n",
    "location_name=[]\n",
    "skills=[]\n",
    "\n",
    "\n",
    "# job info\n",
    "job_titles=soup.find_all('h2',{'class':'css-m604qf'})\n",
    "\n",
    "company_names=soup.find_all('a',{'class':'css-17s97q8'})\n",
    "\n",
    "location_names=soup.find_all('span',{'class':'css-5wys0k'})\n",
    "\n",
    "job_skills=soup.find_all('div',{'class':'css-y4udm8'})\n",
    "\n",
    "\n",
    "# iterate over list to extract needed info into othter list\n",
    "for i in range(len(job_titles)):\n",
    "    job_title.append(job_titles[i].text)\n",
    "    company_name.append(company_names[i].text)\n",
    "    location_name.append(location_names[i].text)\n",
    "    skills.append(job_skills[i].text)\n",
    "    \n",
    "    \n",
    "print(company_name)\n",
    "print()\n",
    "print(job_title)\n",
    "print()\n",
    "print(skills)\n",
    "\n",
    "file_list=[job_title,company_name,location_name,skills]\n",
    "\n",
    "exported=zip_longest(*file_list)\n",
    "\n",
    "with open(f\"C:/Users/NIPEAL/OneDrive/Desktop/projectss/py_project_githubs/web_scraping/ws_jobs_web/jobstest.csv\" , 'w',encoding='utf-8') as f:\n",
    "    wr=csv.writer(f)\n",
    "    wr.writerow(['job title', 'company name', 'locaton','skills'])\n",
    "    wr.writerows(\n",
    "         exported\n",
    "    )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from itertools import zip_longest\n",
    "\n",
    "#fetch url\n",
    "result=requests.get(\"https://wuzzuf.net/search/jobs/?q=python&a=hpb\")\n",
    "\n",
    "#save page content/markup\n",
    "src= result.content\n",
    "\n",
    "#create soup object to parse content\n",
    "soup=BeautifulSoup(src,'lxml')\n",
    "\n",
    "\n",
    "job_title=[]\n",
    "company_name=[]\n",
    "location_name=[]\n",
    "skills=[]\n",
    "\n",
    "#links for every job to get deep description about it\n",
    "links=[]\n",
    "\n",
    "\n",
    "# job info\n",
    "job_titles=soup.find_all('h2',{'class':'css-m604qf'})\n",
    "\n",
    "company_names=soup.find_all('a',{'class':'css-17s97q8'})\n",
    "\n",
    "location_names=soup.find_all('span',{'class':'css-5wys0k'})\n",
    "\n",
    "job_skills=soup.find_all('div',{'class':'css-y4udm8'})\n",
    "\n",
    "\n",
    "# iterate over list to extract needed info into othter list\n",
    "for i in range(len(job_titles)):\n",
    "    job_title.append(job_titles[i].text)\n",
    "    links.append(job_titles[i].find('a').attrs['href'])\n",
    "    company_name.append(company_names[i].text)\n",
    "    location_name.append(location_names[i].text)\n",
    "    skills.append(job_skills[i].text)\n",
    "    \n",
    "    \n",
    "# iterate on every links to get more descriptions for each job\n",
    "for link in links:\n",
    "    result=requests.get(link)\n",
    "    src=result.content\n",
    "    soup=BeautifulSoup(src,'lxml')\n",
    "    salaries=soup.find_all('div',{'class':'css-rcl8e5'})\n",
    "    print(salaries)\n",
    "    \n",
    "\n",
    "\n",
    "# file_list=[job_title,company_name,location_name,skills,links]\n",
    "\n",
    "# exported=zip_longest(*file_list)\n",
    "\n",
    "# with open(f\"C:/Users/NIPEAL/OneDrive/Desktop/projectss/py_project_githubs/web_scraping/ws_jobs_web/jobstest.csv\" , 'w',newline='',encoding='utf-8') as f:\n",
    "#     wr=csv.writer(f)\n",
    "#     wr.writerow(['job title', 'company name', 'locaton','skills','links'])\n",
    "#     wr.writerows(\n",
    "#          exported\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://wuzzuf.net/jobs/p/gSlIpqMnrkqV-Senior-Python-Developer-Nile-Bits-LLC-Giza-Egypt'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3663947768.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    i=\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "i=\n",
    "# iterate on every links to get more descriptions for each job\n",
    "for link in links:\n",
    "    if i==0:\n",
    "        result=requests.get(r'https://wuzzuf.net/jobs/p/gSlIpqMnrkqV-Senior-Python-Developer-Nile-Bits-LLC-Giza-Egypt?o=1&l=sp&t=sj&a=python|search-v3|hpb')\n",
    "        src=result.content\n",
    "        soup=BeautifulSoup(src,'html.parser')\n",
    "        salaries = soup.prettify()\n",
    "        \n",
    "        print(salaries)\n",
    "        i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"77f9d92dee9492ce2ad30852d54b6ada\")>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    " \n",
    "# Creating a webdriver instance\n",
    "chrome_driver_path = \"C:/chromedriver-win64/chromedriver.exe\"\n",
    "service = Service(chrome_driver_path)\n",
    "\n",
    "# This instance will be used to log into LinkedIn\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Opening linkedIn's login page\n",
    "driver.get(\"https://linkedin.com/uas/login\")\n",
    " \n",
    "# waiting for the page to load\n",
    "time.sleep(5)\n",
    " \n",
    "# entering username \n",
    "username = driver.find_element(By.ID, \"username\")\n",
    " \n",
    "# In case of an error, try changing the element\n",
    "# tag used here.\n",
    " \n",
    "# Enter Your Email Address\n",
    "username.send_keys(\"\")  \n",
    " \n",
    "# entering password\n",
    "pword = driver.find_element(By.ID, \"password\")\n",
    "# In case of an error, try changing the element \n",
    "# tag used here.\n",
    " \n",
    "# Enter Your Password\n",
    "pword.send_keys(\"\")        \n",
    " \n",
    "# Clicking on the log in button\n",
    "# Format (syntax) of writing XPath --> \n",
    "# //tagname[@attribute='value']\n",
    "driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
    "# In case of an error, try changing the\n",
    "# XPath used here.\n",
    "\n",
    "\n",
    "\n",
    "# Opening Kunal's Profile\n",
    "# paste the URL of Kunal's profile here\n",
    "profile_url = \"https://www.linkedin.com/in/kunalshah1/\"\n",
    " \n",
    "driver.get(profile_url)  \n",
    "driver\n",
    "\n",
    "#dd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it look like every search text it split and %20 contcate between \n",
    "# https://www.linkedin.com/search/results/all/?keywords=python%20develope&origin=AUTO_COMPLETE&searchId=d3032ec4-e4b9-4eca-a57a-ff5119b7cd97&sid=RCj&spellCorrectionEnabled=false"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
